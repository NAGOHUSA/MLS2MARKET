#!/usr/bin/env python3
"""
Enhanced Property Scraper with Images & Public Data
"""
import json
import re
import requests
from bs4 import BeautifulSoup
import urllib.parse
from datetime import datetime
import random

class EnhancedPropertyScraper:
    """Scrapes property data, images, and public records"""
    
    def scrape_enhanced(self, url):
        """Enhanced scraping with images and public data"""
        print(f"üîç Enhanced scraping: {url}")
        
        # First, get basic property data
        basic_data = self.scrape_basic(url)
        
        # Try to get property image
        basic_data['images'] = self.extract_images(url, basic_data.get('address', ''))
        
        # Enhance with public data (free APIs and simulated data)
        enhanced_data = self.add_public_data(basic_data)
        
        # Add visual ratings
        enhanced_data['ratings'] = self.generate_ratings(enhanced_data)
        
        # Add valuation analysis
        enhanced_data['valuation'] = self.analyze_valuation(enhanced_data)
        
        return enhanced_data
    
    def scrape_basic(self, url):
        """Basic property data scraping (reuses existing logic)"""
        # Reuse your existing scraping logic here
        # This is a simplified version
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            data = {
                'source_url': url,
                'scraped_at': datetime.now().isoformat(),
                'address': self.extract_address(soup),
                'price': self.extract_price(soup),
                'beds': self.extract_number(soup, ['bed', 'bd', 'br']),
                'baths': self.extract_number(soup, ['bath', 'ba']),
                'sqft': self.extract_number(soup, ['sqft', 'square', 'sq ft']),
                'year_built': self.extract_year(soup),
                'property_type': self.extract_property_type(soup),
                'description': self.extract_description(soup)[:500]
            }
            
            # Add MLS ID if found
            data['mls_id'] = self.extract_mls_id(soup, url)
            
            return data
            
        except Exception as e:
            print(f"Error in basic scrape: {e}")
            return self.get_sample_data(url)
    
    def extract_images(self, url, address):
        """Extract property images from listing"""
        images = []
        
        try:
            # Try to find images in the page
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Common image patterns in real estate sites
            img_selectors = [
                'img[src*="property"]',
                'img[src*="photo"]', 
                'img[src*="image"]',
                'img[class*="photo"]',
                'img[class*="property"]',
                'img[data-src*="http"]',
                'picture img',
                '.gallery img',
                '.slideshow img'
            ]
            
            for selector in img_selectors:
                for img in soup.select(selector):
                    src = img.get('src') or img.get('data-src')
                    if src and src.startswith('http') and any(ext in src.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                        if len(images) < 3:  # Limit to 3 images
                            images.append({
                                'url': src,
                                'caption': img.get('alt', address)
                            })
            
            # If no images found, use placeholder or sample
            if not images:
                images.append({
                    'url': f"https://source.unsplash.com/600x400/?house,{address.split(',')[0].replace(' ', '+')}",
                    'caption': address,
                    'is_placeholder': True
                })
            
        except Exception as e:
            print(f"Image extraction error: {e}")
            # Use Unsplash as fallback
            images.append({
                'url': "https://source.unsplash.com/600x400/?real-estate,house",
                'caption': "Property Image",
                'is_placeholder': True
            })
        
        return images
    
    def add_public_data(self, property_data):
        """Add free public data about location"""
        address = property_data.get('address', '')
        
        # Simulated public data - in production, integrate with free APIs:
        # 1. OpenStreetMap (free) for location data
        # 2. US Census API (free) for demographic data
        # 3. Local government open data portals
        # 4. Free weather APIs
        
        public_data = {
            'neighborhood': self.guess_neighborhood(address),
            'coordinates': self.estimate_coordinates(address),
            'crime_data': self.estimate_crime_data(address),
            'school_data': self.estimate_school_data(address),
            'transportation': self.get_transportation_score(address),
            'amenities': self.get_nearby_amenities(address),
            'environmental': self.get_environmental_data(address)
        }
        
        property_data['public_data'] = public_data
        return property_data
    
    def generate_ratings(self, data):
        """Generate color-coded ratings for various factors"""
        address = data.get('address', '')
        
        # Simulated ratings - in production, use actual public data
        ratings = {
            'school_quality': {
                'score': random.randint(65, 95),
                'color': self.score_to_color(random.randint(65, 95)),
                'details': 'Based on district test scores and parent reviews'
            },
            'safety': {
                'score': random.randint(70, 98),
                'color': self.score_to_color(random.randint(70, 98)),
                'details': 'Crime statistics and neighborhood safety'
            },
            'transportation': {
                'score': random.randint(60, 90),
                'color': self.score_to_color(random.randint(60, 90)),
                'details': 'Access to public transit and major roads'
            },
            'amenities': {
                'score': random.randint(75, 95),
                'color': self.score_to_color(random.randint(75, 95)),
                'details': 'Parks, shopping, restaurants nearby'
            },
            'investment_potential': {
                'score': random.randint(70, 92),
                'color': self.score_to_color(random.randint(70, 92)),
                'details': 'Price trends and market demand'
            },
            'environment': {
                'score': random.randint(80, 100),
                'color': self.score_to_color(random.randint(80, 100)),
                'details': 'Air quality and environmental factors'
            }
        }
        
        # Calculate overall score
        scores = [r['score'] for r in ratings.values()]
        ratings['overall'] = {
            'score': sum(scores) // len(scores),
            'color': self.score_to_color(sum(scores) // len(scores)),
            'label': self.score_to_label(sum(scores) // len(scores))
        }
        
        return ratings
    
    def analyze_valuation(self, data):
        """Analyze property valuation and market position"""
        price = data.get('price', 500000)
        sqft = data.get('sqft', 2000)
        
        # Calculate price per sqft
        price_per_sqft = price / sqft if sqft > 0 else 250
        
        # Market analysis (simulated)
        market_data = {
            'listing_price': price,
            'price_per_sqft': round(price_per_sqft, 2),
            'market_position': self.analyze_market_position(price, address=data.get('address', '')),
            'comparable_sales': self.get_comparable_sales(price, sqft),
            'price_trend': self.get_price_trend(),
            'appreciation_potential': self.get_appreciation_potential()
        }
        
        return market_data
    
    # Helper methods for data simulation
    def score_to_color(self, score):
        """Convert score to color code"""
        if score >= 90:
            return '#10B981'  # Green
        elif score >= 80:
            return '#34D399'  # Light Green
        elif score >= 70:
            return '#FBBF24'  # Yellow
        elif score >= 60:
            return '#F59E0B'  # Orange
        else:
            return '#EF4444'  # Red
    
    def score_to_label(self, score):
        """Convert score to text label"""
        if score >= 90: return 'Excellent'
        elif score >= 80: return 'Very Good'
        elif score >= 70: return 'Good'
        elif score >= 60: return 'Fair'
        else: return 'Needs Attention'
    
    def analyze_market_position(self, price, address=''):
        """Analyze if price is competitive"""
        # Simulated analysis
        positions = ['Below Market', 'Competitive', 'Premium', 'Overpriced']
        # Use address hash to get consistent result for same address
        hash_val = hash(address) % 100
        if hash_val < 20: return positions[0]
        elif hash_val < 60: return positions[1]
        elif hash_val < 85: return positions[2]
        else: return positions[3]
    
    def get_comparable_sales(self, price, sqft):
        """Generate comparable sales data"""
        comparables = []
        base_price = price
        base_sqft = sqft
        
        for i in range(3):
            price_var = random.randint(-15, 15)  # -15% to +15%
            sqft_var = random.randint(-200, 200)  # -200 to +200 sqft
            age_var = random.randint(-5, 10)  # -5 to +10 years
            
            comparables.append({
                'address': f'{1234 + i} Comparable St',
                'price': round(base_price * (1 + price_var/100)),
                'sqft': base_sqft + sqft_var,
                'price_per_sqft': round((base_price * (1 + price_var/100)) / (base_sqft + sqft_var), 2),
                'sold_date': f'{2024 - random.randint(0, 2)}-{random.randint(1, 12):02d}',
                'similarity': random.randint(75, 95)
            })
        
        return comparables
    
    def get_price_trend(self):
        """Get price trend data"""
        trends = ['Rising', 'Stable', 'Declining', 'Volatile']
        return random.choice(trends)
    
    def get_appreciation_potential(self):
        """Estimate appreciation potential"""
        potentials = ['High', 'Moderate', 'Low', 'Stable']
        return random.choice(potentials)
    
    # Additional helper methods for address parsing
    def extract_address(self, soup):
        """Extract address from soup"""
        # Multiple methods to find address
        selectors = [
            'meta[property="og:title"]',
            'h1[class*="address"]',
            'title',
            '[data-testid="address"]',
            '.address'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                text = element.get('content') or element.get_text()
                if 'address' in selector.lower() or '123' not in text:
                    return text.strip()[:100]
        
        return "Property Address"
    
    def extract_price(self, soup):
        """Extract price from soup"""
        text = soup.get_text()
        patterns = [r'\$\s*(\d{1,3}(?:,\d{3})+)', r'Price:\s*\$?(\d{1,3}(?:,\d{3})+)']
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return int(match.group(1).replace(',', ''))
        return random.randint(300000, 800000)
    
    def get_sample_data(self, url):
        """Fallback sample data"""
        return {
            'address': 'Sample Property',
            'price': 450000,
            'beds': 3,
            'baths': 2.5,
            'sqft': 2000,
            'year_built': 1995,
            'property_type': 'Single Family Home',
            'mls_id': 'SAMPLE-' + url[-8:].replace('/', ''),
            'source_url': url
        }

def main():
    """Test the enhanced scraper"""
    import sys
    scraper = EnhancedPropertyScraper()
    
    if len(sys.argv) > 1:
        url = sys.argv[1]
        data = scraper.scrape_enhanced(url)
        
        print(f"Address: {data.get('address')}")
        print(f"Price: ${data.get('price'):,}")
        print(f"Images found: {len(data.get('images', []))}")
        print(f"Ratings generated: {len(data.get('ratings', {}))}")
        
        # Save to file
        with open('enhanced_scrape.json', 'w') as f:
            json.dump(data, f, indent=2)
        
        print("‚úì Enhanced data saved to enhanced_scrape.json")
    else:
        print("Usage: python enhanced_scraper.py <url>")

if __name__ == "__main__":
    main()
